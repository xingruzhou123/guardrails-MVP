# config/rails.yml

input_rails:
  # --- LAYER 1: The Gatekeeper ---
  # This rule runs first. It uses a precise Regex to immediately block any
  # input that contains known sensitive technical terms.
  - name: block_sensitive_tech_input
    type: "regex"
    pattern: "(?i)(branch\\s*predict(or|ion)|cache|micro[- ]?arch|pipeline|PBT|BTB|prediction\\s*table)"
    on_fail: "block"

  # --- LAYER 2: The Intent Classifier ---
  # If the input is not blocked by the gatekeeper, this rule then checks
  # for helpful, actionable intents.
  - name: llm_intent_classifier
    type: "llm_classifier"
    description: "Detects user intents and extracts entities using an LLM."
    top_k: 5
    intents:
      - name: "query_product_price"
        description: "User is asking about the price, cost, or availability of a specific product."
        entities:
          product_name: "The specific product the user is asking about."
        examples:
          - "How much is the Ryzen 9 processor?"
          - "What's the price for a Zen 4 CPU?"
          - "Tell me the cost of the new graphics card."

      - name: "control_robot_arm"
        description: "User is giving a command to a physical or simulated robot arm."
        entities:
          action: "The verb describing the action (e.g., 'pick up', 'move', 'grab')."
          target_object: "The noun or object the action is directed at (e.g., 'red block', 'blue sphere')."
        examples:
          - "Command the robot arm to pick up the red block."
          - "Use the arm to move the blue sphere."

output_rails:
  # --- LAYER 3: The Final Safety Net ---
  # As a final protection, this rule checks the main LLM's output,
  # in case a sensitive topic was phrased in a way that bypassed the input rails.
  - name: block_sensitive_amd_info
    type: "regex"
    pattern: "(?i)(AMD|Ryzen|Zen\\s*\\d+).*(branch\\s*predict(or|ion)|cache|micro[- ]?arch|pipeline|PBT|BTB|prediction\\s*table)"
    on_fail: "block"

  - name: llama_semantic_guard
    type: "llm_check"
    model: "meta-llama/Llama-Guard-3-1b"
    on_fail: "allow"

